{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96df84dd-434a-49d6-855b-e290ef0c36fd",
   "metadata": {},
   "source": [
    "# OpenAI dev  \n",
    "https://platform.openai.com/docs/overview  \n",
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d52e39-15fe-4f47-9686-7b51204fd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI # Not free - class has sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77714ed6-9cbc-4fbd-9a78-6b1b35ad4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eeb20ae-fdff-4284-859b-65e95a5c39b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here’s a workflow for developing a regression model in scikit-learn given a dataset from a URL that contains categorical variables and missing values. I’ll give you a typical Python code outline and explain each step.\n",
      "\n",
      "**Assumed URL:**  \n",
      "Replace `YOUR_URL_HERE` with your actual data file URL.\n",
      "\n",
      "---\n",
      "\n",
      "### Workflow Steps\n",
      "\n",
      "#### 1. **Read the data**\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "url = 'YOUR_URL_HERE'\n",
      "df = pd.read_csv(url)\n",
      "```\n",
      "\n",
      "#### 2. **Explore the data**\n",
      "\n",
      "- Identify columns with missing values.\n",
      "- Identify categorical vs. numerical columns.\n",
      "\n",
      "```python\n",
      "print(df.info())\n",
      "print(df.head())\n",
      "print(df.isnull().sum())\n",
      "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
      "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
      "```\n",
      "\n",
      "#### 3. **Split features and target**\n",
      "\n",
      "Suppose your target variable is `'y'`. Replace as appropriate.\n",
      "\n",
      "```python\n",
      "X = df.drop('y', axis=1)\n",
      "y = df['y']\n",
      "```\n",
      "\n",
      "#### 4. **Set up preprocessing for columns**\n",
      "\n",
      "We will:\n",
      "- Impute missing values (mean for numerics, most common for categoricals)\n",
      "- Encode categoricals (OneHotEncoder is recommended)\n",
      "- Use ColumnTransformer to apply the transformations\n",
      "\n",
      "```python\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "# Numeric preprocessing (impute mean)\n",
      "num_pipeline = Pipeline(steps=[\n",
      "    ('imputer', SimpleImputer(strategy='mean')),\n",
      "])\n",
      "\n",
      "# Categorical preprocessing (impute most frequent + one-hot encode)\n",
      "cat_pipeline = Pipeline(steps=[\n",
      "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
      "])\n",
      "\n",
      "preprocessor = ColumnTransformer(transformers=[\n",
      "    ('num', num_pipeline, numerical_cols),\n",
      "    ('cat', cat_pipeline, categorical_cols),\n",
      "])\n",
      "```\n",
      "\n",
      "#### 5. **Create a pipeline with regressor**\n",
      "\n",
      "Example regressor (use any regressor, such as RandomForestRegressor, Ridge, etc.)\n",
      "\n",
      "```python\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.pipeline import Pipeline\n",
      "\n",
      "regression_pipeline = Pipeline(steps=[\n",
      "    ('preprocessor', preprocessor),\n",
      "    ('regressor', RandomForestRegressor())\n",
      "])\n",
      "```\n",
      "\n",
      "#### 6. **Train-test split**\n",
      "\n",
      "```python\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "```\n",
      "\n",
      "#### 7. **Fit model**\n",
      "\n",
      "```python\n",
      "regression_pipeline.fit(X_train, y_train)\n",
      "```\n",
      "\n",
      "#### 8. **Evaluate**\n",
      "\n",
      "```python\n",
      "from sklearn.metrics import mean_squared_error, r2_score\n",
      "\n",
      "y_pred = regression_pipeline.predict(X_test)\n",
      "print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
      "print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## Summary Table\n",
      "\n",
      "| Step                 | Code/Purpose                                                             |\n",
      "|----------------------|--------------------------------------------------------------------------|\n",
      "| **Read Data**        | `pd.read_csv(url)`                                                       |\n",
      "| **Explore**          | `df.info()`, `df.isnull().sum()`, etc.                                   |\n",
      "| **Select Features**  | `X = df.drop('y', axis=1); y = df['y']`                                  |\n",
      "| **Build Preprocessor**| Use `ColumnTransformer` to create pipelines for num/cat columns         |\n",
      "| **Model Pipeline**   | Wrap preprocessor + regressor in a Pipeline                              |\n",
      "| **Train/Test Split** | `train_test_split`                                                       |\n",
      "| **Fit Model**        | `pipeline.fit(X_train, y_train)`                                         |\n",
      "| **Evaluate**         | `mean_squared_error`, `r2_score`                                         |\n",
      "\n",
      "---\n",
      "\n",
      "### **Further Enhancements**\n",
      "- Use GridSearchCV for hyperparameter tuning.\n",
      "- Try different imputers, encoders, or regressors.\n",
      "- Scale features if needed.\n",
      "- Analyze feature importances.\n",
      "\n",
      "---\n",
      "\n",
      "**If you share the actual data URL and specify the regression target, I can refine this workflow into executable code custom to your dataset.**\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key = api_key)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Read in data from this url and provide a workflow to develop a regression model using scikitlearn. There are categorical variables that wil need to be encoded and missing values that we want to impute.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe073e0-d527-4675-9759-9c400b24d77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
